__base__: "general.yaml"
seed: 42
log:
  name: "defaultname"
  dir: "" # default save to /output/exp
  tensorboard_log_interval: 7  # Log losses every N steps

checkpoint:
  resume: false        # 是否从断点恢复
  resume_path: "/workspace/gan_seg/outputs/exp/20251124_061700/checkpoints/step_7000.pt"
  overwrite_flow_predictor: true
  overwrite_flow_path: "/workspace/zeroflow_weights/argo/chamfer/checkpoint_epoch=049_step=0000078750_epoch_end.ckpt"
  save_every_iters: 500
model:
  flow:
    name: "FastFlow3D"
    lr: 2e-7
    FastFlow3D:
      VOXEL_SIZE: [0.2, 0.2, 6]
      PSEUDO_IMAGE_DIMS: [512, 512]
      POINT_CLOUD_RANGE: [-51.2, -51.2, -3, 51.2, 51.2, 3]
      FEATURE_CHANNELS: 32
      SEQUENCE_LENGTH: 2
  mask:
    name: "Sonata" #MaskFormer3D or PTV3 or Sonata
    lr: 1e-6
    weight_decay: 0.0001
    block_lr_scale: 0.1
    slot_num: 10
    lr_decay: 0.7
    lr_decay_step: 80000
    lr_clip: 1e-7
    MaskFormer3D:
      n_slot: 64
      n_point: 32768
      use_xyz: true
      bn: true
      n_transformer_layer: 4
      transformer_embed_dim: 256
      transformer_input_pos_enc: false
      scale: 2
    PTV3:
      in_channels: 3  # xyz coordinates
      feat_dim: 256
      grid_size: 0.1  # Grid size for voxelization (10cm)
      enable_flash: true  # Enable flash attention (requires CUDA >= 11.6)
      enable_rpe: false  # Relative position encoding (disabled when flash attention is enabled)
      enc_depths: [2,2, 2, 6, 2]  # Encoder depths for each stage
      enc_channels: [32,64, 128, 256, 512]  # Encoder channels for each stage
      dec_depths: [1, 1, 1, 1]  # Decoder depths
      dec_channels: [512, 512, 512, 256]  # Decoder channels
      # Self-supervised pretrained model (Sonata)
      # pretrained_name: "Sonata-Small"  # Use Sonata self-supervised pretrained model
      # Alternative options:
      # pretrained_path: "/workspace/sonata_small.pth"  # Local path to pretrained weights (.pth or .pt file)
      # pretrained_name: "scannet-semseg-pt-v3m1-0-base"  # Supervised pretrained model from HuggingFace
    Sonata:
      in_channels: 3  # xyz coordinates
      feat_dim: 256
      grid_size: 0.01  # Grid size for voxelization (10cm)
      enable_flash: true  # Enable flash attention (requires CUDA >= 11.6)
      enable_rpe: false  # Relative position encoding (disabled when flash attention is enabled)
      # Sonata model name: "sonata" (default) or "sonata_small"
      model_name: "sonata"  # Use Sonata self-supervised pretrained model
      repo_id: "facebook/sonata"  # HuggingFace repository ID
      # Alternative: use local checkpoint path
      # pretrained_path: "/workspace/sonata.pth"  # Local path to pretrained weights
      # Custom config to override model config (optional)
      # custom_config:
      #   enc_patch_size: [1024, 1024, 1024, 1024, 1024]
      #   enable_flash: false

dataset:
  name: "MOVI_FSequence"
  AV2_SceneFlowZoo:
    point_size: 32768
    root_dir: "/workspace/av2data/train"
    subsequence_length: 2
    sliding_window_step_size: 1
    with_ground: true
    with_rgb: false
    eval_type: "bucketed_epe"
    expected_camera_shape: (194, 256, 3)
    cache_root: "/workspace/av2data/cache"
    use_gt_flow: false
    flow_data_path: "/workspace/av2flow/train/"
    min_instance_size: 50
  MOVI_FSequence:
    dataset_path: "/workspace/movi/0"
    motion_threshold: 0.01
    max_k: 3
  val_name: "MOVI_FSequence"
  AV2_SceneFlowZoo_val_flow:
    point_size: 32768
    root_dir: "/workspace/av2data/val"
    with_ground: true
    with_rgb: false
    eval_type: "bucketed_epe"
    expected_camera_shape: (194, 256, 3)
    use_gt_flow: true
    cache_root: "/workspace/av2data/cache"
    flow_data_path: "/workspace/av2flow/val/"
    eval_args_output_path: "eval_results/bucketed_epe/nsfp_distillation_1x/"
  AV2_SceneFlowZoo_val_mask:
    point_size: 32768
    root_dir: "/workspace/av2data/val"
    with_ground: false
    with_rgb: false
    eval_type: "bucketed_epe"
    expected_camera_shape: (194, 256, 3)
    use_gt_flow: false
    cache_root: "/workspace/av2data/cache"
    flow_data_path: "/workspace/av2flow/val/"
    eval_args_output_path: "eval_results/bucketed_epe/nsfp_distillation_1x/"
    min_instance_size: 50
lr_multi:
  rec_loss: 0
  flow_loss: 0.0
  scene_flow_smoothness: 0.1
  rec_flow_loss: 0.0
  point_smooth_loss: 0.1
  eular_flow_loss: 0.0
  KDTree_loss: 0
  KNN_loss: 4
  l1_regularization: 0.0
  eular_mask_loss: 0
  invariance_loss: 0.1
  scene_flow_smoothness_scheduler:
    begin_iter: 0
    end_iter: 8000
    begin_value: 1.0
    end_value: 1.0

# alternate:
#   flow: [[50,false],[50,true]]
#   mask: [[50,true],[50,false]]
training:
  use_icp_inference_flow: false
  max_iter: 300000
  eval_loop: 100
  begin_train_smooth: 0
  begin_train_point_smooth: 3000
  begin_train_flow: 20000
  begin_train_mask: 0
  begin_train_invariance: 7500
  begin_train_singular_value: 6000
  mask_downsample_factor: 1
  # loss_downsample_num: 32768
  grad_accumulation_steps: 4
  augment_params:
    regression_center_point: [true, true, true]
    angle_range: [-1.4, 1.4]
    rotate_axis: "z"
    translation_range: [1, 1,0.2]
    scale_range: [0.95, 1.05]
    mirror_x: true
    mirror_z: false
dataloader:
  batchsize: 1
  val_batchsize: 16
  num_workers: 8
loss:
  scale_flow_magnitude: 1
  clamp_flow_magnitude: 100
  scene_flow_smoothness:
    square_mask: true 
    scale_flow_grad: 0.00001
    each_mask_item:
      relative_gradient: 1
      criterion: "L2"
    sum_mask_item:
      relative_gradient: 0
      criterion: "L2"
    singular_value_loss_gradient: 0.001
  point_smooth_loss:
    knn_loss_params:
      k: 32
      radius: 1.
      loss_norm: 1
    ball_q_loss_params:
      k: 64
      radius: 2.
      loss_norm: 1
  knn:
    ignore_ground: false
    k: 1
    reduction: "none"
    distance_max_threshold: 2
    distance_min_threshold: 0.0
    background_threshold: 0.05
  reconstruction_loss:
    using_legend_loss: false
vis:
  show_window: false
  debug_grad: false

eval:
  eval_size: 20
  eval_flow_size: 20
  eval_mask_size: 20
  min_points: 50
  ignore_class_ids: [-1,0]

